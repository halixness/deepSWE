======= REFERENZE
- https://github.com/Showmax/kinetics-downloader
- https://github.com/CannyLab/tsne-cuda

======= RAGIONAMENTO
    - Normali AE hanno il problema di essere deterministici e approssimare i possibili outcome
    - I VAE lavorano su variabili continue, ma non risolvono il problema: con A->B e A->C, la rete darà A->(B+C) senza capire un mapping unico
        https://arxiv.org/pdf/1312.6114v10.pdf
    - I VQ-VAE forse risolvono questo problema
        https://arxiv.org/pdf/1711.00937v2.pdf
    - Potrei usare l'attenzione almeno sul tempo?

======= xx/04/2021 =======

- Creato un dataloader per servire batch dinamicamente
- Aggiunto il supporto di caricamento completo in ram del dataset
- Aggiunto l'algoritmo Second Chance per minimizzare gli accessi da disco


======= x1/05/2021 =======

- Implementata la standardizzazione per canale del dataset in input
- Passaggio Keras -> PyTorch per maggiore customizzazione e test di modelli esistenti
- Valutazione del framework FLAX per futuro scaling up ad architettura tpu

======= 13/05/2021 =======

- Scelta di PyTorch come main framework al momento (maggiore familiarità, più referenze online)
- Test della prima architettura: Autoencoder
    - Bottleneck:   Resnet 64-128-256-512
    - Decoder:      ConvTranspose3d + BatchNorm
    - Osservazioni:
        1) Il modello prevede degli output "sovrapposti" con intensità variabili, sembra essere segno del problema dei modelli deterministici
        2) Testando con reti più profonde e più epochs, le previsioni sono più nitide, ma non si risolve il problema 1)
        3) Bisogna verificare quando i frame cambiano molto tra di loro (al momento non sembra...)
        4) Sembra che le previsioni del modello siano tutte molto simili tra di loro
- Next TODO:
    [x] Attenzione: partitions.get_train() va convertito in get_all, bisogna togliere train-test split da li!
    [x] Capire meglio se per ogni datapoint c'è una significativa differenza tra frames, nel caso testare meglio con il simulatore nel cluster
    [x] normalizzazione pericolosa per le velocità
    [ ] Testare la rete con sequenze di frame che variano molto
    [ ] Cercare di visualizzare lo spazio latente dell'autoencoder
    [ ] prova data augmentation con rotazione delle immagini
    [ ] capire k frame passato per ottenere un buon frame prossimo futuro
    [ ] possibilmente passare a lettura on-the-fly da disco, dato che anche la normalizzazione è fatta con partial fit
    [ ] migrare al cluster, adattare lo script per esecuzioni asincrone

======= 16/05/2021 =======

- Refactoring del dataloader
    - Migliorato l'algoritmo di windowing: aumentati i frames utilizzabili
    - Risolto il problema delle sequenze: ci sono differenze significative tra i frames in sequenza
- Primo test DEP+VEL+BTM, (frame_past, frame_future):
    - (4-6), (6, 2): risultati molto sfocati

======= 17/05/2021 =======

- Proseguimento del primo test
    - Si nota una periodicità nella loss (picchi), da indagare

======= 20/05/2021 =======

- Secondo test DEP+VEL:
    - La mappa BTM non è molto nitida, da capire se va bene (analizza)
    - Cambia poco, molta sfocatura ma forse meno valori elevati fuori dal bacino
    - Con più epochs (50 -> 100) la loss continua a scendere un po'
    - Da trasferirsi sul cluster

======= 30/05/2021 =======

- Cambiamenti:
    - Rete semplificata al minimo, aumentato spazio latente (32x32), ridotti i canali: sembra previsione più nitida
    - Ridotto la batch size, potrebbe far fatica a generalizzare troppi sample
    - Sistemato caching difettoso nel data loader
- Osservazioni:
    - Il caching fornisce una netta velocizzazione nel data loading
    - Forse una batch size più bassa migliora l'apprendimento
- Risolti problemi:
    - Il training sembra più sensato con una rete più semplice + caching risolto
    - La loss non oscilla più se: aumento il num. di frames futuri + riduco la batch size
- Problemi:
    - la sequenza, andando avanti nel batch, ha due direzioni: asciutto->flooded, flooded->asciutto
      causa di ambiguità?
    - Non credo la misura d'errore sia troppo affidabile
    - Filtri più grossi -> da errore dimensione, da testare

======= 01/06/2021 =======
======= 08/06/2021 =======

- batch size = 1 meglio?
[x] batch size: solo sequenze della stessa area per batch?
    [x] batch troppo grosso: 33 sequenze -> creare più batch con size variabile (non sempre divisibili), basta che abbiano sequenze della stessa area!
    [x] PROBLEMA: cache hit ratio = 0, lento loading
[X] normalizzazione: basta impostare che il minimo sia 0, senza variare la dev std!!
    [x] DEP niente
    [x] BTM: trova minimo e sottrailo
[X] valutare senza batch normalization
- kernel più grande = anche usare una risoluzione più bassa (sintetizzare), possibile da implementare nel dataloader (downsample, 1x, 2x) con filtro gaussiano
- NON aumentare i filtri

- fornire in input nuove sequenze con frame futuri predetti
- prevedere tanti frame futuri in 1 volta non serve


======= 11/06/2021 =======
[x] La rete performa in base all'inizializzazione random dei pesi. Al momento c'è l'inizializzazione He: https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch
    - era il learning rate
[x] Dopo un certo numero di epochs, la rete "collassa" le previsioni in una matrice dai pattern strani, e la loss può scendere o salire
    - era il learning rate

[x] Come si comporta in modalità autoregressivo?

Ipotesi:
[x] trovare una inizializzazione sempre valida per i pesi
    - learning rate più basso (1e-3) forse aiuta meglio ed evita il collasso (ottimo!!)
- cambiare misure accuratezza (non sono molto valide)


======= 14/06/2021 =======
- Modalità autoregressiva (1 frame per volta inserito nuovamente in input, sliding window):
    - non mi sembra stia facendo molto, anzi a volte peggiora: non prevede aumenti di altezza d'acqua
- Modalità sequenza frame futuri generati con conv3d:
    - prevede meglio l'aumento d'acqua rispetto all'altra modalità (19,25,39,53, 55, 56)
    - sospetto a volte che non preveda bene: approssima con lo stesso frame futuro (46)
- Idee:
    - stabilire una metrica che valuti la qualità della sequenza frame: somiglianza dell'andamento dei valori (non valore medio per forza)
    - testare su un dataset più ampio
    - valutare le previsioni su un dataset totalmente nuovo (baganza o altri)

======= 16/06/2021 =======
- Rafactoring, modello intercambiabile

======= 22/06/2021 =======
- Preparazione dataset e ambiente sul cluster HPC

======= 26/06/2021 =======
- Test del modello con dataset nuovi (Baganza)


======= 28/06/2021 =======
- metrica con focus sulle aree in cui veramente cambia di piú
- modulo velocitá: mappa di attenzione
- max scarto (con attenzione) tra i frames della sequenza in input, cosí da filtrare per inserire nel dataset
- max wse al posto del frame a metà per la scansione delle aree di focus in con cut
- tracciare andamento di un movimento (verifica task di video prediction)


1) aumento la frequenza di campionamento nel tempo
2) downsampling su mappa totale
3) testare in scratch un training sullo stesso dataset
4) presentazione di tutti i processi, idee del lavoro

======= 30/06/2021 =======
======= 04/07/2021 =======
[x] max scarto (con attenzione) tra i frames della sequenza in input, cosí da filtrare per inserire nel dataset
[x] max wse al posto del frame a metà per la scansione delle aree di focus in con cut

[x] testare l'allenamento con dataset raw 10min
    - problema: le celle inutili sono di intralcio nel calcolo della loss/accuracy, per questo la rete approssima troppo male
      idea: bisogna usare la mappa delle velocità come "attention map"
      ----> sta funzionando! [ ] bisogna provare a incorporare questo nella rete neurale
      idea: la vision attention forse può funzionare meglio di conv2d in questo caso!

[ ] provare a filtrare le sequenze con la nuova metrica
    - idea: genera tutte le sequenze, quindi crea n vettori per area (all'interno num. variabile di sequenze), idealmente scarta i batch residui che non raggiungono batch_size per un'area
[ ] testare il modello contro dataset con frequenze di campionamento diverse (challenge)


======= 05/07/2021 =======
Task:
1) implementare il filtro sequenza nel dataloader
2) provare il training con il nuovo dataset 10/7 min filtrato
3) testare con una rete più profonda (o più hidden features)
4) testare con un learning rate più basso/alto
5) prova a togliere la velocità dall'input

======= 12/07/2021 =======
Punti da riunione:
- Non fornire vettore unico velocitá, tenerli separati
- Maschera attenzione: trovare un modo per calcolarla per il modello, velocitá non molto affidabile

======= 22/07/2021 =======

[x] usa vvx e vvy separati
[x] ConvLSTM
- usa MANNING oltre a BTM
- UNet + LSTM
- loss: somma profonditá previsione = somma profonditá y_true
- 102s nel futuro con 9 quadrati -> cioé entro 3x3 quadrati vedo eventi (102 secondi di finestra temporale)
- input: 9 celle profonditá, output: 1 cella centrale

H = altezza massima
G = 9,8
- deltaT = 0,5*Lato quadrato / root(G*H)
- deltaT —> per la simulazione
deltaT = lasso di tempo prevedibile per considerare l'influenza di eventi entro L celle

1) simulazione ogni minuto
2) input 3x3 e output 1x1 centrale, tutti i canali 

problemi:
    - con UNet non posso modificare il decoder: le skip connections richiedono matrici uguali.
      Quindi provo a far prevedere tutta la griglia 3x3
    - al peggio: cambio architettura rete neurale, uso il semplice autoencoder

======= 02/08/2021 =======
- Riesco ad eseguire con ConvLSTM
- Implementata custom loss da valutare: custom + MSE? o custom + SSIM?
- problemi:
    - le previsioni contengono anche il terreno, inoltre gli output della rete sono negativi!
      forse devo creare un'architettura  (autoencoder) con funzioni relu
    - valutare alternative a ConvLSTM: https://holmdk.github.io/2020/04/02/video_prediction.html

======= 11/08/2021 =======

- Generazione dataset 3x3 grid
- Training su grid 3x3 con valutazione dei risultati, inizio training su porzione di dataset estesa
- Inizio test con modalitá autoregressiva, da testare anche LSTM many-to-many

======= 15/08/2021 =======

- Impostazione rete neurale per il dataset 3x3 grid
- Verifica ultime statistiche training

======= TODO =======
Done    Priority    Task
[ ]     1           Aumenta i frame passati, sperimenta autoregressiva e 1tomany
[ ]     2           Stampare le previsioni dal file tests + invia risultati
[ ]     2           Pensa alla modalitá on the fly di nuovo
[ ]     3           Migliora la metrica
[ ]     4           Scrivere la documentazione su github
[ ]     5           Refactoring PyTorch Lightning, multiple gpus + tpus


