{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_lightning import preloading\n",
    "from utils.data_lightning import otf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mat\n",
    "import matplotlib as mpl\n",
    "import argparse\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from models.ae import seq2seq_ConvLSTM\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Session folder: runs/train_110_31_08_2021_12_36_34\n",
      "[x] 24 areas found\n",
      "Area 0 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[4%] 21 valid sequences loaded\n",
      "Area 1 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[8%] 21 valid sequences loaded\n",
      "Area 2 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[12%] 21 valid sequences loaded\n",
      "Area 3 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[17%] 21 valid sequences loaded\n",
      "Area 4 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[21%] 21 valid sequences loaded\n",
      "Area 5 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[25%] 21 valid sequences loaded\n",
      "Area 6 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[29%] 21 valid sequences loaded\n",
      "Area 7 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[33%] 21 valid sequences loaded\n",
      "Area 8 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[38%] 21 valid sequences loaded\n",
      "Area 9 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[42%] 21 valid sequences loaded\n",
      "Area 10 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[46%] 21 valid sequences loaded\n",
      "Area 11 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[50%] 21 valid sequences loaded\n",
      "Area 12 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[54%] 21 valid sequences loaded\n",
      "Area 13 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[58%] 21 valid sequences loaded\n",
      "Area 14 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x - - - - - - \n",
      "[62%] 20 valid sequences loaded\n",
      "Area 15 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x - - - - - - \n",
      "[67%] 20 valid sequences loaded\n",
      "Area 16 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[71%] 21 valid sequences loaded\n",
      "Area 17 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x x - - x x x x x x x x x x x - - - - - \n",
      "[75%] 22 valid sequences loaded\n",
      "Area 18 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[79%] 21 valid sequences loaded\n",
      "Area 19 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[83%] 21 valid sequences loaded\n",
      "Area 20 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[88%] 21 valid sequences loaded\n",
      "Area 21 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[92%] 21 valid sequences loaded\n",
      "Area 22 - sequences: 35\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "[96%] 0 valid sequences loaded\n",
      "Area 23 - sequences: 35\n",
      "- - - - - - x x x x x x x x x x - - - x x x x x x x x x x x - - - - - \n",
      "[100%] 21 valid sequences loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------- Functions\n",
    "\n",
    "def rss_loss(input, target):\n",
    "    return th.sum((target - input) ** 2)\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "   \n",
    "# -------------- Setting up the run\n",
    "\n",
    "num_run = len(os.listdir(\"runs/\")) + 1\n",
    "now = datetime.now()\n",
    "foldername = \"train_{}_{}\".format(num_run, now.strftime(\"%d_%m_%Y_%H_%M_%S\"))\n",
    "os.mkdir(\"runs/\" + foldername)\n",
    "weights_path = \"runs/\" + foldername + \"/model.weights\"\n",
    "\n",
    "print(\"[!] Session folder: {}\".format(\"runs/\" + foldername))\n",
    "\n",
    "writer = SummaryWriter(\"runs/\" + foldername)\n",
    "\n",
    "# -------------------------------\n",
    "plotsize = 15\n",
    "\n",
    "dataset = preloading.SWEDataModule(\n",
    "    root=\"../datasets/arda/old_256/\",\n",
    "    test_size=0.1,\n",
    "    val_size=0,\n",
    "    past_frames=4,\n",
    "    future_frames=1,\n",
    "    partial=None,\n",
    "    filtering=True,\n",
    "    batch_size=4,\n",
    "    workers=4,\n",
    "    image_size=192,\n",
    "    shuffle=False,\n",
    "    dynamicity=2e-1,\n",
    "    caching=False,\n",
    "    downsampling=True\n",
    ")\n",
    "\n",
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[!] It's training time!\n"
     ]
    }
   ],
   "source": [
    "# ---- Model\n",
    "net = seq2seq_ConvLSTM.EncoderDecoderConvLSTM(nf=32, in_chan=4, out_chan=3)\n",
    "\n",
    "# Parallelism\n",
    "if th.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = th.device(dev)\n",
    "\n",
    "if th.cuda.device_count() > 1:\n",
    "  print(\"[!] Yay! Using \", th.cuda.device_count(), \"GPUs!\")\n",
    "  net = nn.DataParallel(net)\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "# ---- Training time!\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-4, weight_decay=1e-2) # L2, Ridge Regression\n",
    "# L1 Lasso Regression --> https://medium.com/analytics-vidhya/understanding-regularization-with-pytorch-26a838d94058\n",
    "losses = []\n",
    "avg_losses = []\n",
    "errors = []\n",
    "test_errors = []\n",
    "print(\"\\n[!] It's training time!\")\n",
    "\n",
    "epochs = 200\n",
    "plot_graph = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, target, threshold = 1e-2):\n",
    "\n",
    "    total = (target * prediction).cpu().detach().numpy()\n",
    "    total = np.array(total > 0).astype(int) # TP + TN + FP + FN\n",
    "\n",
    "    diff = np.abs((target - prediction).cpu().detach().numpy())\n",
    "    correct_cells = (diff < threshold).astype(int)\n",
    "    correct_cells = correct_cells*total # TP + TN\n",
    "\n",
    "    accuracy = np.sum(correct_cells)/np.sum(total)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Study/Tesi Laurea/deepSWE/models/ae/seq2seq_ConvLSTM.py:49: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for t in range(seq_len):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109it [00:07, 14.99it/s, fwd_time=0.0145, loss=6.54e+3, query_time=0.0165, test_acc=0.177, train_acc=0.152] \n",
      "\n",
      "avg.loss 0.00\ttook 6539.29 s\tavg. inference time 7.35 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 1\n",
      "109it [00:05, 19.56it/s, fwd_time=0.0141, loss=4.46e+3, query_time=0.0161, test_acc=0.4, train_acc=0.398]  \n",
      "\n",
      "avg.loss 1.00\ttook 4459.56 s\tavg. inference time 5.67 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 2\n",
      "109it [00:05, 20.19it/s, fwd_time=0.014, loss=3.45e+3, query_time=0.0155, test_acc=0.45, train_acc=0.457]  \n",
      "\n",
      "avg.loss 2.00\ttook 3453.52 s\tavg. inference time 5.50 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 3\n",
      "109it [00:05, 19.88it/s, fwd_time=0.0142, loss=2.84e+3, query_time=0.0154, test_acc=0.481, train_acc=0.471]\n",
      "\n",
      "avg.loss 3.00\ttook 2842.58 s\tavg. inference time 5.57 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 4\n",
      "109it [00:05, 19.11it/s, fwd_time=0.0145, loss=2.42e+3, query_time=0.0165, test_acc=0.493, train_acc=0.491]\n",
      "\n",
      "avg.loss 4.00\ttook 2419.04 s\tavg. inference time 5.80 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 5\n",
      "109it [00:05, 18.97it/s, fwd_time=0.0145, loss=2.11e+3, query_time=0.0171, test_acc=0.502, train_acc=0.525]\n",
      "\n",
      "avg.loss 5.00\ttook 2114.40 s\tavg. inference time 5.85 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 6\n",
      "109it [00:05, 18.91it/s, fwd_time=0.0145, loss=1.89e+3, query_time=0.0168, test_acc=0.494, train_acc=0.533]\n",
      "\n",
      "avg.loss 6.00\ttook 1885.44 s\tavg. inference time 5.86 s\tavg.query time/batch 0.01 s\n",
      "---- Epoch 7\n",
      "35it [00:01, 18.51it/s, fwd_time=0.0151, loss=1.83e+3, query_time=0.0183, test_acc=0.395, train_acc=0.368]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f941ce36f58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# first time plot the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"---- Epoch {}\".format(epoch))\n",
    "    epoch_start = time.time()\n",
    "    training_times = []\n",
    "    query_times = []\n",
    "    query_start = time.time()\n",
    "\n",
    "    iter_dataset = tqdm(enumerate(dataset.train_dataloader()), file=sys.stdout)\n",
    "    for i, batch in iter_dataset:\n",
    "        query_end = time.time()\n",
    "        query_times.append(query_end-query_start)\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "\n",
    "        # first time plot the graph\n",
    "        if not plot_graph:\n",
    "            writer.add_graph(net, x)\n",
    "            writer.close()\n",
    "            plot_graph = True\n",
    "\n",
    "        # ---- Predicting\n",
    "        start = time.time()\n",
    "        outputs = net(x, 1)  # 0 for layer index, 0 for h index\n",
    "\n",
    "        # ---- Batch Loss\n",
    "        loss = rss_loss(outputs[:, :3, 0, :, :], y[:, 0, :3, :, :])\n",
    "        acc = accuracy(outputs[:, :3, 0, :, :], y[:, 0, :3, :, :], threshold=1e-1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end = time.time()\n",
    "        training_times.append(end - start)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        query_start = time.time()\n",
    "        \n",
    "        # ----- Testing\n",
    "        size = len(dataset.datasets[1] )\n",
    "        random_test_batch = dataset.datasets[1][random.randint(0, size-1)]\n",
    "        x_test, y_test = batch\n",
    "        x_test = x_test.float().to(device)\n",
    "        y_test = y_test.float().to(device)\n",
    "        test_outputs = net(x_test, 1) \n",
    "        test_acc = accuracy(test_outputs[:, :3, 0, :, :], y_test[:, 0, :3, :, :], threshold=1e-1)\n",
    "\n",
    "        writer.add_scalar('test_accuracy',\n",
    "                      test_acc,\n",
    "                      epoch*len(dataset.train_dataloader())+i)\n",
    "\n",
    "        writer.add_scalar('train_accuracy',\n",
    "                          acc,\n",
    "                          epoch*len(dataset.train_dataloader())+i)\n",
    "\n",
    "        # Plot values\n",
    "        if i % 3:\n",
    "            writer.add_scalar('avg training loss',\n",
    "                              np.mean(losses),\n",
    "                              epoch)\n",
    "            \n",
    "        iter_dataset.set_postfix(\n",
    "            loss=np.mean(losses),\n",
    "            train_acc=acc,\n",
    "            test_acc=test_acc,\n",
    "            fwd_time=np.mean(training_times),\n",
    "            query_time=np.mean(query_times)\n",
    "        )\n",
    "\n",
    "    epoch_end = time.time()\n",
    "    print(\"\\navg.loss {:.2f}\\ttook {:.2f} s\\tavg. inference time {:.2f} s\\tavg.query time/batch {:.2f} s\"\n",
    "          .format(epoch, np.mean(losses), epoch_end-epoch_start, np.mean(training_times), np.mean(query_times)))\n",
    "    avg_losses.append(np.mean(losses))\n",
    "\n",
    "    # checkpoint weights\n",
    "    th.save(net.state_dict(), weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print('[!] Finished Training, storing final weights...')\n",
    "\n",
    "# Loss plot\n",
    "mpl.rcParams['text.color'] = 'k'\n",
    "\n",
    "plt.title(\"average loss\")\n",
    "plt.plot(range(len(avg_losses)), avg_losses)\n",
    "plt.savefig(\"runs/\" + foldername + \"/avg_loss.png\")\n",
    "plt.clf()\n",
    "\n",
    "print(\"Avg.training time: {}\".format(np.mean(training_times)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Tesi Laurea)",
   "language": "python",
   "name": "pycharm-b3d8d961"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
