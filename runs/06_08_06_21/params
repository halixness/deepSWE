==============================
Epochs			20
Batch size		1
Past frames		6
Future frames		1
Batch shuffle       ON
Sequence shuffle    ON
DEP, VVX, BTM
==============================

[0,    32] train_err: 14.193 	  test_err: 13.532 	 avg_loss: 0.298
[0,   100] train_err: 1.001 	  test_err: 1.006 	 avg_loss: 1.524
[0,    87] train_err: 0.965 	  test_err: 0.977 	 avg_loss: 0.830
[0,    55] train_err: 0.975 	  test_err: 0.979 	 avg_loss: 0.596
[0,    65] train_err: 0.971 	  test_err: 0.967 	 avg_loss: 0.472
[0,    83] train_err: 0.972 	  test_err: 0.976 	 avg_loss: 0.399
[0,   104] train_err: 0.983 	  test_err: 0.972 	 avg_loss: 0.348
[0,   105] train_err: 0.983 	  test_err: 0.971 	 avg_loss: 0.313
[0,    21] train_err: 0.982 	  test_err: 0.987 	 avg_loss: 0.286
[0,    43] train_err: 0.975 	  test_err: 0.985 	 avg_loss: 0.265
[0,     6] train_err: 0.983 	  test_err: 0.971 	 avg_loss: 0.250
[2,    53] train_err: 0.971 	  test_err: 0.982 	 avg_loss: 0.177
[2,    69] train_err: 0.983 	  test_err: 0.970 	 avg_loss: 0.173
[2,    56] train_err: 0.983 	  test_err: 0.979 	 avg_loss: 0.171
[2,    98] train_err: 0.963 	  test_err: 0.965 	 avg_loss: 0.169
[2,    73] train_err: 0.973 	  test_err: 0.975 	 avg_loss: 0.166
[2,    68] train_err: 0.951 	  test_err: 0.950 	 avg_loss: 0.163
[2,    95] train_err: 0.981 	  test_err: 0.974 	 avg_loss: 0.161
[2,    41] train_err: 0.973 	  test_err: 0.983 	 avg_loss: 0.158
[2,    69] train_err: 0.980 	  test_err: 0.966 	 avg_loss: 0.156
[2,    95] train_err: 0.982 	  test_err: 0.975 	 avg_loss: 0.154
[2,    84] train_err: 0.983 	  test_err: 0.977 	 avg_loss: 0.153
[4,    66] train_err: 0.983 	  test_err: 0.978 	 avg_loss: 0.141
[4,    60] train_err: 0.972 	  test_err: 0.968 	 avg_loss: 0.140
[4,    69] train_err: 0.982 	  test_err: 0.968 	 avg_loss: 0.139
[4,    42] train_err: 0.984 	  test_err: 0.986 	 avg_loss: 0.139
[4,    91] train_err: 0.977 	  test_err: 0.959 	 avg_loss: 0.138
[4,    25] train_err: 0.977 	  test_err: 0.976 	 avg_loss: 0.137
[4,    80] train_err: 0.985 	  test_err: 0.978 	 avg_loss: 0.136
[4,    64] train_err: 0.982 	  test_err: 0.977 	 avg_loss: 0.135
[4,     3] train_err: 0.962 	  test_err: 0.971 	 avg_loss: 0.135
[4,    31] train_err: 0.973 	  test_err: 0.972 	 avg_loss: 0.134
[4,    47] train_err: 0.978 	  test_err: 0.968 	 avg_loss: 0.133
[6,     4] train_err: 0.970 	  test_err: 0.984 	 avg_loss: 0.128
[6,    15] train_err: 0.983 	  test_err: 0.971 	 avg_loss: 0.128
[6,    21] train_err: 0.976 	  test_err: 0.982 	 avg_loss: 0.128
[6,    51] train_err: 0.985 	  test_err: 0.972 	 avg_loss: 0.128
[6,    15] train_err: 0.977 	  test_err: 0.961 	 avg_loss: 0.127
[6,    52] train_err: 0.974 	  test_err: 0.959 	 avg_loss: 0.127
[6,    64] train_err: 0.980 	  test_err: 0.974 	 avg_loss: 0.127
[6,    81] train_err: 0.977 	  test_err: 0.985 	 avg_loss: 0.126
[6,    72] train_err: 0.961 	  test_err: 0.976 	 avg_loss: 0.126
[6,    11] train_err: 0.980 	  test_err: 0.963 	 avg_loss: 0.125
[6,    90] train_err: 0.978 	  test_err: 0.981 	 avg_loss: 0.125
[8,    19] train_err: 0.982 	  test_err: 0.967 	 avg_loss: 0.122
[8,   105] train_err: 0.983 	  test_err: 0.971 	 avg_loss: 0.122
[8,    62] train_err: 0.980 	  test_err: 0.966 	 avg_loss: 0.122
[8,    68] train_err: 0.973 	  test_err: 0.972 	 avg_loss: 0.122
[8,    61] train_err: 0.972 	  test_err: 0.977 	 avg_loss: 0.122
[8,   100] train_err: 0.961 	  test_err: 0.979 	 avg_loss: 0.122
[8,    23] train_err: 0.984 	  test_err: 0.972 	 avg_loss: 0.121
[8,    57] train_err: 0.976 	  test_err: 0.980 	 avg_loss: 0.121
[8,    24] train_err: 0.961 	  test_err: 0.977 	 avg_loss: 0.121
[8,    66] train_err: 0.980 	  test_err: 0.973 	 avg_loss: 0.121
[8,     6] train_err: 0.982 	  test_err: 0.968 	 avg_loss: 0.121
[10,    65] train_err: 0.981 	  test_err: 0.981 	 avg_loss: 0.119
[10,    48] train_err: 0.970 	  test_err: 0.970 	 avg_loss: 0.119
[10,    73] train_err: 0.982 	  test_err: 0.983 	 avg_loss: 0.119
[10,    66] train_err: 0.985 	  test_err: 0.980 	 avg_loss: 0.119
[10,    47] train_err: 0.972 	  test_err: 0.959 	 avg_loss: 0.119
[10,    28] train_err: 0.961 	  test_err: 0.956 	 avg_loss: 0.118
[10,    84] train_err: 0.985 	  test_err: 0.980 	 avg_loss: 0.118
[10,     9] train_err: 0.977 	  test_err: 0.981 	 avg_loss: 0.118
[10,    29] train_err: 0.973 	  test_err: 0.975 	 avg_loss: 0.118
[10,    10] train_err: 0.966 	  test_err: 0.981 	 avg_loss: 0.118
[10,    71] train_err: 0.979 	  test_err: 0.968 	 avg_loss: 0.118
[12,    60] train_err: 0.971 	  test_err: 0.968 	 avg_loss: 0.116
[12,    84] train_err: 0.983 	  test_err: 0.978 	 avg_loss: 0.116
[12,    34] train_err: 0.968 	  test_err: 0.968 	 avg_loss: 0.116
[12,    41] train_err: 0.971 	  test_err: 0.982 	 avg_loss: 0.116
[12,    90] train_err: 0.971 	  test_err: 0.976 	 avg_loss: 0.116
[12,    66] train_err: 0.975 	  test_err: 0.967 	 avg_loss: 0.116
[12,    38] train_err: 0.973 	  test_err: 0.984 	 avg_loss: 0.116
[12,    21] train_err: 0.981 	  test_err: 0.985 	 avg_loss: 0.116
[12,    72] train_err: 0.965 	  test_err: 0.978 	 avg_loss: 0.116
[12,    30] train_err: 0.981 	  test_err: 0.980 	 avg_loss: 0.116
[12,    33] train_err: 0.966 	  test_err: 0.982 	 avg_loss: 0.116
[14,    22] train_err: 0.969 	  test_err: 0.982 	 avg_loss: 0.115
[14,    12] train_err: 0.969 	  test_err: 0.982 	 avg_loss: 0.115
[14,    77] train_err: 0.966 	  test_err: 0.968 	 avg_loss: 0.115
[14,     6] train_err: 0.982 	  test_err: 0.969 	 avg_loss: 0.115
[14,    27] train_err: 0.957 	  test_err: 0.957 	 avg_loss: 0.115
[14,    98] train_err: 0.948 	  test_err: 0.950 	 avg_loss: 0.115
[14,    29] train_err: 0.981 	  test_err: 0.983 	 avg_loss: 0.114
[14,    77] train_err: 0.972 	  test_err: 0.973 	 avg_loss: 0.114
[14,    67] train_err: 0.975 	  test_err: 0.969 	 avg_loss: 0.114
[14,    81] train_err: 0.978 	  test_err: 0.985 	 avg_loss: 0.114
[14,    49] train_err: 0.979 	  test_err: 0.983 	 avg_loss: 0.114
[16,    45] train_err: 0.984 	  test_err: 0.971 	 avg_loss: 0.113
[16,    80] train_err: 0.983 	  test_err: 0.976 	 avg_loss: 0.113
[16,   102] train_err: 0.965 	  test_err: 0.982 	 avg_loss: 0.113
[16,     5] train_err: 0.982 	  test_err: 0.971 	 avg_loss: 0.113
[16,   101] train_err: 0.971 	  test_err: 0.974 	 avg_loss: 0.113
[16,     0] train_err: 0.954 	  test_err: 0.951 	 avg_loss: 0.113
[16,    20] train_err: 0.979 	  test_err: 0.975 	 avg_loss: 0.113
[16,    63] train_err: 0.971 	  test_err: 0.971 	 avg_loss: 0.113
[16,    74] train_err: 0.983 	  test_err: 0.971 	 avg_loss: 0.113
[16,     8] train_err: 0.987 	  test_err: 0.978 	 avg_loss: 0.113
[16,   102] train_err: 0.967 	  test_err: 0.984 	 avg_loss: 0.113
[18,    57] train_err: 0.971 	  test_err: 0.975 	 avg_loss: 0.112
[18,    77] train_err: 0.969 	  test_err: 0.971 	 avg_loss: 0.112
[18,    39] train_err: 0.965 	  test_err: 0.977 	 avg_loss: 0.112
[18,    68] train_err: 0.961 	  test_err: 0.960 	 avg_loss: 0.112
[18,    40] train_err: 0.972 	  test_err: 0.953 	 avg_loss: 0.112
[18,    92] train_err: 0.975 	  test_err: 0.968 	 avg_loss: 0.112
[18,    15] train_err: 0.987 	  test_err: 0.975 	 avg_loss: 0.112
[18,    33] train_err: 0.970 	  test_err: 0.984 	 avg_loss: 0.112
[18,    88] train_err: 0.969 	  test_err: 0.980 	 avg_loss: 0.112
[18,    97] train_err: 0.975 	  test_err: 0.977 	 avg_loss: 0.112
[18,    60] train_err: 0.971 	  test_err: 0.968 	 avg_loss: 0.112
==============================
 kernel_size = 3
padding = 1

self.layers = nn.ModuleList([
nn.Conv3d(channels, 8, kernel_size=kernel_size, stride=1, padding=padding),
nn.AvgPool3d((1,2,2)),

ResNetBlock(in_filters = 8, filters = 8, stride = 2, kernel_size=kernel_size, padding=padding),

nn.Conv3d(8, 16, (1,1,1)),
ResNetBlock(in_filters = 16, filters = 16, stride = 2, kernel_size=kernel_size, padding=padding),

nn.Conv3d(16, 32, (1,1,1)),
ResNetBlock(in_filters = 32, filters = 32, stride = (2,1,1), kernel_size=kernel_size, padding=padding),

nn.Conv3d(32, 64, (1,1,1)),
ResNetBlock(in_filters = 64, filters = 64, stride = 1, kernel_size=kernel_size, padding=padding),

# ----------------------

nn.ConvTranspose3d(64, 32, (1,2,2), stride=(1,2,2)),
#nn.BatchNorm3d(num_features=32),

nn.ConvTranspose3d(32, 16, (1,2,2), stride=(1,2,2)),
#nn.BatchNorm3d(num_features=16),

nn.ConvTranspose3d(16, 8, (1,2,2), stride=(1,2,2)),
#nn.BatchNorm3d(num_features=8),

nn.ConvTranspose3d(8, 8, (1,1,1), stride=(1,1,1)),
#nn.BatchNorm3d(num_features=8),

nn.ConvTranspose3d(8, 1, (1,1,1), stride=(1,1,1)),

