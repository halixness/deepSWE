{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Study/Tesi Laurea/models/utils/dataloader.py:265: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if accesses is not 0:\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import DataPartitions, DataGenerator\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "plotsize = 15\n",
    "\n",
    "partitions = DataPartitions(\n",
    "    past_frames=6,\n",
    "    future_frames=2,\n",
    "    root=\"../datasets/baganza/10min/\",\n",
    "    partial=0.3\n",
    ")\n",
    "\n",
    "dataset = DataGenerator(\n",
    "    root=\"../datasets/baganza/10min/\",\n",
    "    dataset_partitions=partitions.get_partitions(),\n",
    "    past_frames=partitions.past_frames, \n",
    "    future_frames=partitions.future_frames,\n",
    "    input_dim=(partitions.past_frames, 256, 256, 3),\n",
    "    output_dim=(partitions.future_frames, 256, 256, 2),\n",
    "    batch_size=4,\n",
    "    buffer_size=1e3,\n",
    "    buffer_memory=100,\n",
    "    downsampling=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "U8pHltaOy2CK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if th.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = th.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "        \n",
    "    def __init__(self, in_filters, filters, stride, kernel_size, padding):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.c1 = nn.Conv3d(in_filters, filters, kernel_size, stride, padding=padding)\n",
    "        self.c2 = nn.Conv3d(filters, filters, kernel_size, padding=padding)\n",
    "        self.c3 = nn.Conv3d(in_filters, filters, (1, 1, 1), stride)\n",
    "        \n",
    "        #self.bn = nn.BatchNorm3d(num_features=filters)\n",
    "\n",
    "    def forward(self, x,):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        y = self.c1(x)\n",
    "\n",
    "        #y = self.bn(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.c2(y)\n",
    "        #y = self.bn(y)\n",
    "\n",
    "        # reshape\n",
    "        if residual.shape != y.shape:\n",
    "            residual = self.c3(residual)\n",
    "            #residual = self.bn(residual)\n",
    "            \n",
    "        return self.activation(residual + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv3d(channels, 8, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.AvgPool3d((1,2,2)),\n",
    "            \n",
    "            ResNetBlock(in_filters = 8, filters = 8, stride = 2, kernel_size=kernel_size, padding=padding),\n",
    "\n",
    "            nn.Conv3d(8, 16, (1,1,1)),\n",
    "            ResNetBlock(in_filters = 16, filters = 16, stride = 2, kernel_size=kernel_size, padding=padding),\n",
    "\n",
    "            nn.Conv3d(16, 32, (1,1,1)),\n",
    "            ResNetBlock(in_filters = 32, filters = 32, stride = (2,1,1), kernel_size=kernel_size, padding=padding),\n",
    "\n",
    "            nn.Conv3d(32, 64, (1,1,1)),\n",
    "            ResNetBlock(in_filters = 64, filters = 64, stride = 1, kernel_size=kernel_size, padding=padding),\n",
    "\n",
    "            # ----------------------\n",
    "\n",
    "            nn.ConvTranspose3d(64, 32, (1,2,2), stride=(1,2,2)),\n",
    "            #nn.BatchNorm3d(num_features=32),\n",
    "\n",
    "            nn.ConvTranspose3d(32, 16, (2,2,2), stride=(2,2,2)),\n",
    "            #nn.BatchNorm3d(num_features=16),\n",
    "\n",
    "            nn.ConvTranspose3d(16, 8, (1,2,2), stride=(1,2,2)),\n",
    "            #nn.BatchNorm3d(num_features=8),\n",
    "\n",
    "            nn.ConvTranspose3d(8, 8, (1,1,1), stride=(1,1,1)),\n",
    "            #nn.BatchNorm3d(num_features=8),\n",
    "            \n",
    "            nn.ConvTranspose3d(8, 2, (1,1,1), stride=(1,1,1)),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, summary = False):\n",
    "        \n",
    "        if summary:\n",
    "            print(\"==== Model Summary ====\")\n",
    "            print(\"{:<15s}{:>4s}\".format(\"Block\", \"Output shape\"))\n",
    "\n",
    "        for i, l in enumerate(self.layers):\n",
    "            x = l(x)\n",
    "            \n",
    "            if summary:\n",
    "                print(\"{:<20s}{:>4s}\".format(\n",
    "                    str(l).split(\"(\")[0],\n",
    "                    str(x.shape).split(\"[\")[1].split(\"]\")[0]\n",
    "                ))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_weights(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        th.nn.init.xavier_uniform(m.weight.data)\n",
    "\n",
    "def sqrt_weights(m):\n",
    "    # https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Model Summary ====\n",
      "Block          Output shape\n",
      "Conv3d              16, 8, 6, 128, 128\n",
      "AvgPool3d           16, 8, 6, 64, 64\n",
      "ResNetBlock         16, 8, 3, 32, 32\n",
      "Conv3d              16, 16, 3, 32, 32\n",
      "ResNetBlock         16, 16, 2, 16, 16\n",
      "Conv3d              16, 32, 2, 16, 16\n",
      "ResNetBlock         16, 32, 1, 16, 16\n",
      "Conv3d              16, 64, 1, 16, 16\n",
      "ResNetBlock         16, 64, 1, 16, 16\n",
      "ConvTranspose3d     16, 32, 1, 32, 32\n",
      "ConvTranspose3d     16, 16, 2, 64, 64\n",
      "ConvTranspose3d     16, 8, 2, 128, 128\n",
      "ConvTranspose3d     16, 8, 2, 128, 128\n",
      "ConvTranspose3d     16, 2, 2, 128, 128\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([16, 2, 2, 128, 128])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Autoencoder(channels=3).to(device)\n",
    "net(th.Tensor(np.random.random((16, 3, 6, 128, 128))).to(device), True).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "errors = []\n",
    "test_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in len(dataset):\n",
    "\n",
    "        X, Y = dataset.__getitem__(i)\n",
    "\n",
    "        # Filtering\n",
    "        X[X > 10e5] = 0\n",
    "        Y[Y > 10e5] = 0\n",
    "\n",
    "        # ->GPU + Permute\n",
    "        X = th.Tensor(X).to(device)\n",
    "        Y = th.Tensor(Y).to(device)\n",
    "        X = X.permute(0, 1, 5, 2, 3, 4)\n",
    "        Y = Y.permute(0, 1, 5, 2, 3, 4)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(X)\n",
    "        \n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # print(\"batch {} - loss {}\".format(i, loss.item()))\n",
    "\n",
    "        if i == len(dataset)-1:\n",
    "            # randomly pick a test batch and compute it\n",
    "            i = np.random.randint(len(Y), size=1)\n",
    "            \n",
    "            train_out = net(X[0])\n",
    "            \n",
    "            #train_err = reverse_ssim(train_out, y_train[i]).item()\n",
    "            #test_err = reverse_ssim(test_out, y_test[i]).item()\n",
    "            train_err = 0\n",
    "\n",
    "            errors.append(train_err)\n",
    "            \n",
    "            print('[%d, %5d] train_err: %.3f \\t avg_loss: %.3f' %\n",
    "                  (epoch, i, train_err, np.mean(losses)))\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        i = np.random.randint(len(dataset))\n",
    "        outputs = net(X)\n",
    "\n",
    "        #------------------------------\n",
    "        fig, axs = plt.subplots(1, outputs[0,0].shape[0], figsize=(plotsize,plotsize))\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "        for i,frame in enumerate(outputs[0,0]):\n",
    "            axs[i].matshow(frame.cpu().detach().numpy())\n",
    "\n",
    "        plt.show()\n",
    "        #------------------------------\n",
    "\n",
    "        #if epoch % 10 == 0:\n",
    "        #    print('[%d, %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, running_loss / 2000))\n",
    "        #    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title(\"loss\")\n",
    "plt.plot(range(len(losses)), losses)\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"relative error\")\n",
    "plt.plot(range(len(errors)), errors, label=\"train\")\n",
    "plt.plot(range(len(test_errors)), test_errors, label=\"test\")\n",
    "plt.legend()\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.color'] = 'w'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "k = np.random.randint(len(X_train))\n",
    "print(\"k = {}\".format(k))\n",
    "#k = 5\n",
    "input = th.unsqueeze(X_train[k,0], 0)\n",
    "outputs = net(input)\n",
    "\n",
    "#------------------------------\n",
    "num_predicted_frames = outputs[0,0].shape[0] # per allineare frames passati e futuri\n",
    "fig, axs = plt.subplots(1, num_predicted_frames, figsize=(plotsize,plotsize))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "for i,frame in enumerate(input[0,0,-num_predicted_frames:]):\n",
    "    frame = frame.cpu().detach().numpy()\n",
    "    axs[i].matshow(frame)\n",
    "    axs[i].set_title('t = {}'.format(i))\n",
    "\n",
    "print(\"======== Past frames ========\")\n",
    "plt.show()\n",
    "\n",
    "print(\"======== True Future vs Predicted frames ========\")\n",
    "\n",
    "#------------------------------\n",
    "fig, axs = plt.subplots(1, num_predicted_frames, figsize=(plotsize,plotsize))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "for i,frame in enumerate(y_train[k,0,0]):\n",
    "    axs[i].matshow(frame.cpu().detach().numpy())\n",
    "    axs[i].set_title('t = {}'.format(i+num_predicted_frames))\n",
    "\n",
    "plt.show()\n",
    "#------------------------------\n",
    "fig, axs = plt.subplots(1, outputs[0,0].shape[0], figsize=(plotsize,plotsize))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "for i,frame in enumerate(outputs[0,0]):\n",
    "    axs[i].matshow(frame.cpu().detach().numpy())\n",
    "\n",
    "plt.show()\n",
    "#------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"k = {}\".format(k))\n",
    "iterations = 4\n",
    "#k = 5\n",
    "\n",
    "input = th.unsqueeze(X_train[k,0], 0)\n",
    "outputs = net(input)\n",
    "\n",
    "#------------------------------\n",
    "print(\"======== Past frames ========\")\n",
    "num_predicted_frames = outputs[0,0].shape[0] # per allineare frames passati e futuri\n",
    "fig, axs = plt.subplots(1, num_predicted_frames, figsize=(plotsize,plotsize))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "for i,frame in enumerate(input[0,0,-num_predicted_frames:]):\n",
    "    axs[i].matshow(frame.cpu().detach().numpy())\n",
    "    axs[i].set_title('t = {}'.format(i))\n",
    "\n",
    "plt.show()\n",
    "#------------------------------\n",
    "print(\"======== True vs Autoregressive Pred Frames  ========\")\n",
    "fig, axs = plt.subplots(1, num_predicted_frames, figsize=(plotsize,plotsize))\n",
    "\n",
    "true_means = []\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "for i,frame in enumerate(y_train[k,0,0]):\n",
    "    axs[i].matshow(frame.cpu().detach().numpy())\n",
    "    axs[i].set_title('t = {}'.format(i+num_predicted_frames))\n",
    "    true_means.append(frame.cpu().detach().numpy().mean())\n",
    "\n",
    "plt.show()\n",
    "#------------------------------\n",
    "\n",
    "#i = np.random.randint(len(X_test))\n",
    "input = th.unsqueeze(X_train[k][0], 0)\n",
    "\n",
    "fig, axs = plt.subplots(1, iterations, figsize=(plotsize,plotsize))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "predicted_means = []\n",
    "for x in range(iterations):\n",
    "    # first predicted frame only\n",
    "    output = th.unsqueeze(net(input)[:,:,0,:,:],2)\n",
    "    # next frame = first predicted from output + btm map\n",
    "    next_frame = output.detach()\n",
    "    next_frame = th.cat((next_frame, th.unsqueeze(input[:,2:,0,:,:],2)), axis=1)\n",
    "    # added on top of (input sequence - first frame)\n",
    "    input = th.cat((next_frame, input[:,:,1:,:]), axis=2)\n",
    "\n",
    "    axs[x].matshow(output[0,0,0].cpu().detach().numpy())\n",
    "    axs[x].set_title('t = {}'.format(x+num_predicted_frames))\n",
    "    predicted_means.append(output[0,0,0].cpu().detach().numpy().mean())\n",
    "    #print(np.mean(output[0,0,0].cpu().detach().numpy()))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Auto regressive mode\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpl.rcParams['text.color'] = 'b'\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(range(len(true_means)), true_means,  \"-b\", label=\"True frames mean\")\n",
    "plt.plot(range(len(true_means)), true_means,  \"*\")\n",
    "\n",
    "plt.plot(range(len(predicted_means)), predicted_means,  \"-g\", label=\"Predicted frames mean\")\n",
    "plt.plot(range(len(predicted_means)), predicted_means,  \"*\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"{:<20s}{:<20s}{:<20s}{:<20s}{:<20s}\".format(\"\", \"min\", \"max\", \"mean\", \"std\"))\n",
    "print(\"{:<20s}{:<20f}{:<20f}{:<20f}{:<20f}\".format(\"prediction\", th.min(outputs), th.max(outputs), th.mean(outputs), th.std(outputs)))\n",
    "print(\"{:<20s}{:<20f}{:<20f}{:<20f}{:<20f}\".format(\"true\", th.min(y_test[0]), th.max(y_test[0]), th.mean(y_test[0]), th.std(y_test[0])))\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "flax_mnist_full_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-b3d8d961",
   "language": "python",
   "display_name": "PyCharm (Tesi Laurea)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}