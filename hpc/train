#!/bin/bash
#SBATCH --job-name=SWE_deepTraining
#SBATCH --output=%x.o%j
#SBATCH --error=%x.e%j
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --gres=gpu:1
#SBATCH --partition=gpu
#SBATCH --mem=32G
#SBATCH --time=23:00:00

# al piu' 128gb di ram per gpu in media
# con il comando 'seff' controllo efficienza memoria
# --gres=gpu:1

module load miniconda3
source "$CONDA_PREFIX/etc/profile.d/conda.sh" 
conda activate swe-cv-pytorch

cd ..
python -u train.py -r ../datasets/arda/output_2021_08_03_1317/mini/ -epochs 500 -lr 0.0001 -p 4


