{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1618502899402,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "eefl0ltHK9A3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1910,
     "status": "ok",
     "timestamp": 1618502901160,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "S9UiTvcPQoWj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7084,
     "status": "ok",
     "timestamp": 1618502906792,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "luYvgoQJQu_Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import CrevNet.pssim.pytorch_ssim as pytorch_ssim\n",
    "from skimage.measure import compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6807,
     "status": "ok",
     "timestamp": 1618502907110,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "Kxm5mQFSROTX"
   },
   "outputs": [],
   "source": [
    "import CrevNet.utils_3d\n",
    "import CrevNet.layers_3d as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1618503373764,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "gYaGAeSPRqFg"
   },
   "outputs": [],
   "source": [
    "rnn_size = 32\n",
    "predictor_rnn_layers = 8\n",
    "batch_size = 16\n",
    "channels = 3\n",
    "image_width = 256\n",
    "lr = 5e-4\n",
    "beta1 = 0.9\n",
    "epoch_size = 5000 # size of epoch\n",
    "niter = 60 # number of epochs\n",
    "optimizer = optim.Adam\n",
    "\n",
    "n_eval = 18 # number of frames to predict at evail time\n",
    "n_past = 10 # train time\n",
    "n_future = 4 # train time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1618503375614,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "5OCBnJv0S-kr",
    "outputId": "ab3e3cec-2bc4-46f5-fb4e-57c7ebb779b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_predictor = model.zig_rev_predictor(rnn_size,  rnn_size, rnn_size, predictor_rnn_layers, batch_size)\n",
    "encoder = model.autoencoder(nBlocks=[4,5,3], nStrides=[1, 2, 2],\n",
    "                    nChannels=None, init_ds=2,\n",
    "                    dropout_rate=0., affineBN=True, in_shape=[channels, image_width, image_width],\n",
    "                    mult=2)\n",
    "\n",
    "frame_predictor_optimizer = optimizer(frame_predictor.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "encoder_optimizer = optimizer(encoder.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "\n",
    "scheduler1 = torch.optim.lr_scheduler.StepLR(frame_predictor_optimizer, step_size=50, gamma=0.2)\n",
    "scheduler2 = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=50, gamma=0.2)\n",
    "\n",
    "\n",
    "# --------- loss functions ------------------------------------\n",
    "mse_criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# --------- transfer to gpu ------------------------------------\n",
    "frame_predictor.cuda()\n",
    "encoder.cuda()\n",
    "mse_criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1618503376449,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "x5LRHzaHSq_w",
    "outputId": "9bf20145-923c-4032-c31b-4db6619cb192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------- transfer to gpu ------------------------------------\n",
    "frame_predictor.cuda()\n",
    "encoder.cuda()\n",
    "mse_criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1618503377722,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "w59QuLHVSuKT"
   },
   "outputs": [],
   "source": [
    "# --------- training funtions ------------------------------------\n",
    "def train(x,e):\n",
    "    frame_predictor.zero_grad()\n",
    "    encoder.zero_grad()\n",
    "\n",
    "    # initialize the hidden state.\n",
    "    frame_predictor.hidden = frame_predictor.init_hidden()\n",
    "    mse = 0\n",
    "\n",
    "    memo = Variable(torch.zeros(batch_size, rnn_size ,3, int(image_width/8), int(image_width/8)).cuda())\n",
    "    for i in range(1, n_past + n_future):\n",
    "        h = encoder(x[i - 1], True)\n",
    "        h_pred,memo = frame_predictor((h,memo))\n",
    "        x_pred = encoder(h_pred,False)\n",
    "        mse +=  (mse_criterion(x_pred, x[i]))\n",
    "\n",
    "\n",
    "    loss = mse\n",
    "    loss.backward()\n",
    "\n",
    "    frame_predictor_optimizer.step()\n",
    "    encoder_optimizer.step()\n",
    "\n",
    "    return mse.data.cpu().numpy() / (n_past + n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P05eqJ1bK9BG"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1618503378510,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "w3lSFr2tK9BH"
   },
   "outputs": [],
   "source": [
    "past_frames = 10\n",
    "future_frames = 4\n",
    "img_size = 256\n",
    "train_size = 0.9\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1618503390109,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "Le5grQitK9BH"
   },
   "outputs": [],
   "source": [
    "root = \"../datasets/baganza/\"\n",
    "porzioni =  os.listdir(root)\n",
    "porzioni = [x for x in sorted(porzioni) if x.startswith(\"mini-\") and os.path.isdir(root +  x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 43883,
     "status": "ok",
     "timestamp": 1618503435448,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "IVbYsrcmK9BI"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  dataset_partitions\n",
    "#       dataset_1\n",
    "#            partition: [start_window_id]\n",
    "#            labels: [ids: id([target_window])]\n",
    "#\n",
    "#       dataset_2\n",
    "#            partition: [start_window_id]\n",
    "#            labels: [ids: id([target_window])]\n",
    "#\n",
    "#       (...)\n",
    "\n",
    "train_dataset_partitions = []\n",
    "test_dataset_partitions = []\n",
    "\n",
    "# Applica intervalli di interesse\n",
    "for area in porzioni:\n",
    "    \n",
    "    n_frames = len([x for x in os.listdir(root + area) if x.endswith(\".DEP\")])\n",
    "\n",
    "    # FIn ai frame che interessano\n",
    "    size = n_frames - past_frames - future_frames\n",
    "    train_len = int(size * train_size)\n",
    "    \n",
    "    partition_raw = []\n",
    "    labels = dict()\n",
    "    \n",
    "    #-----------\n",
    "    for i in range(train_len):\n",
    "        partition_raw.append(\"id-{}\".format(i))\n",
    "        labels[\"id-{}\".format(i)] = list(range(i + (past_frames), i + (past_frames) + (future_frames))) \n",
    "    \n",
    "    train_dataset_partitions.append((partition_raw, labels))\n",
    "    \n",
    "    #-----------\n",
    "    partition_raw = []\n",
    "    labels = dict()\n",
    "    \n",
    "    for i in range(train_len, size):\n",
    "        partition_raw.append(\"id-{}\".format(i))\n",
    "        labels[\"id-{}\".format(i)] = list(range(i + (past_frames), i + (past_frames) + (future_frames))) \n",
    "\n",
    "    test_dataset_partitions.append((partition_raw, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1618503462528,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "z7U1QLlYK9BI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data Generator\n",
    "# Inputs:  \n",
    "#  - Path containing folders of frames\n",
    "#  - List of the names of these folders\n",
    "#  - Partitions: [(ids_x(x, 10), ids_y(x, 4))]\n",
    "#  \n",
    "# TODO: \n",
    "#  - Implementare https://it.wikipedia.org/wiki/Memoria_virtuale#Seconda_scelta_(Algoritmo_dell'orologio)\n",
    "#  - Implementare memory pre-loading per una dimensione consentita\n",
    "#\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, root, filenames, dataset_partitions, batch_size=16, input_dim=(past_frames, img_size, img_size, 3),  output_dim=(future_frames, img_size, img_size, 1), n_channels=1, shuffle=True, buffer_size=0):\n",
    "        'Initialization'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.dataset_partitions = dataset_partitions\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.root = root\n",
    "        self.filenames = filenames\n",
    "\n",
    "        self.buffer = None\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    '''\n",
    "    def buffer_push(self, x):\n",
    "      \n",
    "        if len(self.buffer) > self.buffer_size:\n",
    "          self.buffer.append((x, 1))  \n",
    "        else:\n",
    "          for i in range(len(buffer)):\n",
    "            if not buffer[i][1]:\n",
    "              del buffer[i]\n",
    "              break\n",
    "            else:\n",
    "              buffer[]\n",
    "\n",
    "        self.ram_datasource\n",
    "        return None\n",
    "    '''\n",
    "\n",
    "        \n",
    "    def get_total_frames(self):\n",
    "        'Sum of #frames for each folder'\n",
    "        \n",
    "        total_frames = 0\n",
    "    \n",
    "        for p in self.dataset_partitions:\n",
    "            total_frames += len(p[0])\n",
    "        \n",
    "        return total_frames\n",
    "    \n",
    "    def get_total_batches(self):\n",
    "        'Sum of #batches for each folder'\n",
    "        \n",
    "        batches = 0\n",
    "        \n",
    "        # sum of batches per dataset\n",
    "        for p in self.dataset_partitions:\n",
    "            batches += int(np.floor(len(p[0]) / self.batch_size))\n",
    "            \n",
    "        return batches\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        \n",
    "        return self.get_total_batches()\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "\n",
    "        # Seleziona un intervallo di frames in base all'indice batch\n",
    "        indexes = self.indexes[ index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Shuffles indexes for each epoch, determines total indexes'\n",
    "        \n",
    "        total_frames = self.get_total_frames()\n",
    "            \n",
    "        # Shuffle di tutti gli id frames globali (attinge da più datasets a random)\n",
    "        self.indexes = np.arange(total_frames)\n",
    "        \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def get_dataset_id(self, index):\n",
    "        'Get #folder by #global_frame'\n",
    "        \n",
    "        curmax = 0\n",
    "        \n",
    "        # Get index of which dataset it belongs to\n",
    "        for i, p in enumerate(self.dataset_partitions):\n",
    "            curmax += len(p[0])\n",
    "            if index < curmax:\n",
    "                return i\n",
    "        return -1\n",
    "    \n",
    "    def get_local_id(self, global_id, dataset_id):\n",
    "        'Get #local_frame by #global_frame'\n",
    "        \n",
    "        # remove lens of all the previous ones\n",
    "        for i in range(dataset_id):\n",
    "            global_id -= len(self.dataset_partitions[i][0])\n",
    "        \n",
    "        return global_id\n",
    "        \n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        \n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.input_dim))\n",
    "        y = np.empty((self.batch_size, *self.output_dim))\n",
    "\n",
    "        # Generate data for i IDs\n",
    "        # id: 0 +\n",
    "        for i, global_id in enumerate(list_IDs_temp):\n",
    "            \n",
    "            # Id dataset da cui attingere\n",
    "            # Id frame start nel dataset\n",
    "            dataset_id = self.get_dataset_id(global_id)\n",
    "            local_id = self.get_local_id(global_id, dataset_id)\n",
    "    \n",
    "            # -1 per il BTM che non conta\n",
    "            size = len([x for x in os.listdir(root + self.filenames[dataset_id]) if x.endswith(\".DEP\")])-1\n",
    "            \n",
    "            # Carica file BTM\n",
    "            btm = np.loadtxt(root + self.filenames[dataset_id] + \"/mini-decoded.BTM\")\n",
    "            btm.resize(btm.shape[0], btm.shape[1], 1)\n",
    "            \n",
    "            btm_x = np.tile(btm, (past_frames, 1, 1, 1))\n",
    "            \n",
    "            # Dalla cartella dataset scelta, leggo tutti i frames\n",
    "            deps = None\n",
    "            velocities = None\n",
    "            \n",
    "            # ------ DEP, Velocities train + pred\n",
    "            for j in range(size):\n",
    "                frame = np.loadtxt(root + self.filenames[dataset_id] + \"/mini-decoded-{:04d}.DEP\".format(j))\n",
    "                vvx = np.loadtxt(root + self.filenames[dataset_id] + \"/mini-decoded-{:04d}.VVX\".format(j))\n",
    "                vvy = np.loadtxt(root + self.filenames[dataset_id] + \"/mini-decoded-{:04d}.VVY\".format(j))\n",
    "                velocity = np.sqrt(vvx**2 + vvy**2)\n",
    "                \n",
    "                if deps is None: deps = np.array([frame])\n",
    "                else: deps = np.concatenate((deps, np.array([frame])))\n",
    "                    \n",
    "                if velocities is None: velocities = np.array([velocity])\n",
    "                else: velocities = np.concatenate((velocities, np.array([velocity])))\n",
    "                \n",
    "            deps[deps > 10e5] = 0\n",
    "            velocities[velocities > 10e5] = 0\n",
    "            \n",
    "            # partition[id] -> start position for train window\n",
    "            # ID\n",
    "            # channels, frames, height, width\n",
    "            r = deps[local_id: local_id + past_frames]\n",
    "            r.resize((r.shape[0], r.shape[1], r.shape[2], 1))\n",
    "            \n",
    "            r2 = velocities[local_id: local_id + past_frames]\n",
    "            r2.resize((r2.shape[0], r2.shape[1], r2.shape[2], 1))\n",
    "                        \n",
    "            # frame, channel, width, height\n",
    "            X[i, :,] = np.concatenate((r, r2, btm_x), axis=3)\n",
    "            \n",
    "            # labels[id] -> list of frame indices for predict window\n",
    "            r = deps[self.dataset_partitions[dataset_id][1][\"id-{}\".format(local_id)]]\n",
    "            r.resize((r.shape[0], r.shape[1], r.shape[2], 1))\n",
    "            \n",
    "            y[i, :,] = r\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1618503465488,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "zfUJWB-TK9BK"
   },
   "outputs": [],
   "source": [
    "train_d = DataGenerator(root, porzioni, train_dataset_partitions, batch_size=batch_size)\n",
    "test_d = DataGenerator(root, porzioni, test_dataset_partitions, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244616,
     "status": "ok",
     "timestamp": 1618503711460,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "6--lfZ1sK9BL",
    "outputId": "7e023032-cee2-4a3c-a332-430f3cc52b22"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../datasets/baganza/mini-176-431-6-261/mini-decoded.BTM not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-492477daa5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train - batch # - dep/btm - frame # - w - h - c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-bbadacea1506>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-bbadacea1506>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# Carica file BTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mbtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/mini-decoded.BTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mbtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/parflood/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/parflood/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/parflood/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../datasets/baganza/mini-176-431-6-261/mini-decoded.BTM not found."
     ]
    }
   ],
   "source": [
    "itm = train_d.__getitem__(50)\n",
    "# train - batch # - dep/btm - frame # - w - h - c\n",
    "print(itm[0].shape)\n",
    "print(itm[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1618503747014,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "0JtT0NqtK9BM",
    "outputId": "fd749666-314c-4927-f2a7-5b44e984dff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8dc8ecfdd8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First train frame\n",
    "plt.matshow(itm[0][0][0].reshape(256,256,3)[:, :, 0])\n",
    "\n",
    "# Last target frame\n",
    "plt.matshow(itm[1][0][3].reshape(256, 256)[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-LRzJSPK9BN"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "error",
     "timestamp": 1618504016060,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "WtqoLyRzS1Ji",
    "outputId": "b6d7048d-5890-4297-8f71-e49ffa95ad99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/636 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a80c4ac679e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# x future frames, each has 3 next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-087f89267639>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x, e)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_size\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_past\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mh_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/SWE/Research/models/CrevNet/layers_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, is_predict)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_ch\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_ds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/SWE/Research/models/CrevNet/utils_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_depth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0md_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_depth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size_sq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "# --------- training loop ------------------------------------\n",
    "for epoch in range(niter):\n",
    "    frame_predictor.train()\n",
    "    encoder.train()\n",
    "    epoch_mse = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(train_d))):\n",
    "        \n",
    "        x = torch.Tensor(itm[0])\n",
    "\n",
    "        mse = train(x, i)\n",
    "\n",
    "        # x future frames, each has 3 next \n",
    "        input = []\n",
    "\n",
    "        # for each frame to predict\n",
    "        for j in range(n_eval):\n",
    "            k1 = x[j][:, 0][:,None,None,:,:]\n",
    "            k2 = x[j + 1][:, 0][:,None,None,:,:]\n",
    "            k3 = x[j + 2][:, 0][:,None,None,:,:]\n",
    "\n",
    "            # concatenate sequence of next 3 frames\n",
    "            input.append(torch.cat((k1,k2,k3),2))\n",
    "\n",
    "        mse = 0\n",
    "        mse = train(input, epoch)\n",
    "        epoch_mse += mse\n",
    "        print(\"Loss: {}\".format(mse.item()))\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    '''\n",
    "      ---- Evaluation bit\n",
    "    with torch.no_grad():\n",
    "        frame_predictor.eval()\n",
    "        encoder.eval()\n",
    "\n",
    "        eval = 0\n",
    "        for i in range(100):\n",
    "            x = next(testing_batch_generator)\n",
    "            input = []\n",
    "            for j in range(opt.n_eval):\n",
    "                k1 = x[j][:, 0][:, None, None, :, :]\n",
    "                k2 = x[j + 1][:, 0][:, None, None, :, :]\n",
    "                k3 = x[j + 2][:, 0][:, None, None, :, :]\n",
    "\n",
    "                input.append(torch.cat((k1, k2, k3), 2))\n",
    "            if i == 0:\n",
    "                ssim = plot(input, epoch, True)\n",
    "            else:\n",
    "                ssim = plot(input, epoch)\n",
    "            eval += ssim\n",
    "\n",
    "        print('[%02d] mse loss: %.7f| ssim loss: %.7f(%d)' % (\n",
    "            epoch, epoch_mse / opt.epoch_size,eval/ 100.0, epoch * opt.epoch_size * opt.batch_size))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEDoeTGeUUpk"
   },
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WliVIKsZK9BN"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1617313937691,
     "user": {
      "displayName": "Diego Calanzone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQl0xsN1aGzFIsLt4pNGlQEMoZ6T8dphFIbVB4zQ=s64",
      "userId": "03698100722566364493"
     },
     "user_tz": -120
    },
    "id": "VDFPKqbYK9BN",
    "outputId": "a6f38331-e248-4110-8651-4173cde5babf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 256, 256, 3)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 256, 256, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 256, 256, 32)  128       \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 5, 128, 128, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 5, 128, 128, 64)   55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 128, 128, 64)   256       \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 2, 64, 64, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 4, 128, 128, 64)   110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 128, 128, 64)   256       \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 4, 256, 256, 32)   55328     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 256, 256, 32)   128       \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 4, 256, 256, 1)    865       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 256, 256, 1)    4         \n",
      "=================================================================\n",
      "Total params: 225,605\n",
      "Trainable params: 225,219\n",
      "Non-trainable params: 386\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (batch_size, channels, depth, height, width).\n",
    "sample_shape = (10, 256, 256, 3)\n",
    "inputs = Input(shape = sample_shape)\n",
    "\n",
    "x = inputs\n",
    "\n",
    "x = Conv3D(32, kernel_size=(3, 3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "x = Conv3D(64, kernel_size=(3, 3, 3), padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=64, kernel_size=(3,3,3), strides=(2,2,2), padding=\"same\",activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=32, kernel_size=(3,3,3), strides=(1,2,2), padding=\"same\",activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv3DTranspose(filters=1, kernel_size=(3,3,3), strides=(1,1,1), padding=\"same\",activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "model = Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Biz5ORAbK9BO"
   },
   "outputs": [],
   "source": [
    "#model.compile(optimizer = Adam(learning_rate = 1e-3), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-3), loss = \"mean_absolute_error\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpIhXQ9CK9BP"
   },
   "outputs": [],
   "source": [
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZF2cjXRK9BP",
    "outputId": "298c7fd4-65db-4b61-e30c-202e2eb3aee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      " 63/636 [=>............................] - ETA: 5:30:54 - loss: nan - accuracy: 0.8168"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = train_d,\n",
    "    validation_data = test_d,\n",
    "    use_multiprocessing = True,\n",
    "    workers = 6,\n",
    "    epochs = 1,\n",
    "    callbacks=[history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwGAoO6MK9BP"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(train_d.__getitem__(ind)[0])[0]\n",
    "true = train_d.__getitem__(ind)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBHz_RUCK9BQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(15,5))\n",
    "\n",
    "for i, frame in enumerate(predictions):\n",
    "    axs[i].matshow(frame.reshape(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqAgHB4_K9BQ"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(15,5))\n",
    "\n",
    "for i, frame in enumerate(true):\n",
    "    axs[i].matshow(frame.reshape(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdJUHNItK9BQ"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(4), [np.mean(x) for x in predictions])\n",
    "plt.plot(range(4), [np.mean(x) for x in true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NWLqe98K9BR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 6\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "fig.suptitle('frame 1 - frame 11 pred - frame 11 true')\n",
    "\n",
    "ax1.matshow(train_d.__getitem__(ind)[0][0][0].reshape(256,256))\n",
    "\n",
    "ax2.matshow(model.predict(train_d.__getitem__(ind)[0])[0][0].reshape(256,256))\n",
    "\n",
    "ax3.matshow(train_d.__getitem__(ind)[1][0][0].reshape(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6kgiGfRK9BR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = np.concatenate((train_d.__getitem__(ind)[0][0], train_d.__getitem__(ind)[1][0]))\n",
    "plt.plot(range(14), [np.mean(x) for x in f])\n",
    "\n",
    "plt.plot(range(10, 14), [np.mean(x) for x in model.predict(train_d.__getitem__(ind)[0])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ityoQ-v2K9BR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.accuracy_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RruYcZhCK9BS"
   },
   "outputs": [],
   "source": [
    "history.loss_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZxW2KhXK9BS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01_pytorch_crevnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
